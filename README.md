# RL-Agent-Grid-World Editor

An interactive **GridWorld Editor** and **Value Iteration Simulator** built with Python and Tkinter, designed for creating, editing, saving, and loading custom reinforcement learning environments.  
Perfect for experimenting with **Markov Decision Processes (MDPs)**, **policy/value visualizations**, and **agent path simulations**.


<img width="350" height="400" alt="image" src="https://github.com/user-attachments/assets/e2033780-7658-482b-8c90-6fb023700cad" />

<img width="350" height="400" alt="image" src="https://github.com/user-attachments/assets/2be6682b-2cd8-43af-8598-b886495286a4" />

---

## âœ¨ Features

- **Interactive GUI** built with Tkinter
- Create and modify GridWorld layouts:
  - Place **walls**, **rewards**, and **penalties**
  - Set a custom **start position**
  - Remove any cell configuration
- Change grid size (rows & columns) dynamically
- Adjust **step cost**, reward, and penalty values
- **Save** and **load** custom maps as JSON
- **Preset maps** for quick testing
- Run **Value Iteration** to compute:
  - State value function (**V**)
  - Deterministic policy
- Animate the agent following the computed policy
- Toggle between showing **values** or **policy actions**
- Supports **path visualization** and maintains visited cells

---

## ğŸ“¦ Project Structure

```
RL-Agent-Grid-World/
â”‚
â”œâ”€â”€ images/                  # PNG icons for different cell types & agent
â”‚Â Â  â”œâ”€â”€ empty.png
â”‚Â Â  â”œâ”€â”€ wall.png
â”‚Â Â  â”œâ”€â”€ reward.png
â”‚Â Â  â”œâ”€â”€ penalty.png
â”‚Â Â  â”œâ”€â”€ start.png
â”‚Â Â  â”œâ”€â”€ agent.png
â”‚Â Â  â””â”€â”€ path.png
â”‚
â”œâ”€â”€ saved_maps/              # Saved and preset maps (JSON)
â”‚Â Â  â”œâ”€â”€ preset1.json
â”‚Â Â  â”œâ”€â”€ preset2.json
â”‚Â Â  â”œâ”€â”€ preset3.json
â”‚Â Â  â””â”€â”€ *.json               # Custom user-created maps
â”‚
â”œâ”€â”€ grid.py                  # Core GridWorld environment & dynamics
â”œâ”€â”€ value_iteration.py       # Value iteration algorithm implementation
â”œâ”€â”€ editor.py                # GUI implementation (this file)
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸš€ Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/RezaGooner/RL-Agent-Grid-World.git
   cd RL-Agent-Grid-World
   ```

2. **Install dependencies**  
   This project only requires Pythonâ€™s standard library.  
   Ensure you have **Python 3.8+**.

3. **Ensure images are available**  
   The GUI depends on PNG files in the `images/` directory.

4. **Run the editor**
   ```bash
   python main.py
   ```

---

## ğŸ•¹ï¸ Usage Guide

### Toolbar Modes
- **Wall** â†’ Block movement; removes actions for the cell
- **Reward** â†’ Positive terminal state
- **Penalty** â†’ Negative terminal state
- **Start Point** â†’ Set agent's starting position
- **Delete** â†’ Restore a cell to empty traversable space

### Menu Options
- **File â†’ New** â†’ Reset grid to empty
- **File â†’ Save Current Map** â†’ Save environment as JSON in `saved_maps/`
- **File â†’ Load Preset/Custom Map** â†’ Open loader to pick a preset or saved map
- **Grid â†’ Change Rows & Cols** â†’ Resize the grid
- **Grid â†’ Set Step Cost** â†’ Adjust per-step penalty
- **Grid â†’ Change Reward/Penalty Value** â†’ Adjust terminal state rewards
- **View â†’ Toggle Values/Policy** â†’ Switch between showing value function and policy arrows

### Running Value Iteration
1. Design or load a map
2. Click **Run** (green button) to run Value Iteration
3. Agent will animate following the optimal policy

---

## ğŸ“– How It Works

### Grid Representation
- Every state `(i, j)` has:
  - **Reward** value (`step_cost` by default)
  - **Available actions** from `ACTION_SPACE = ['U', 'D', 'L', 'R']`
  - **Transition probabilities** defined as a dictionary

### Value Iteration
- Imported from `value_iteration.py`
- Computes:
  ```
  V(s) = max_a Î£_s' P(s'|s,a) [ R(s,a,s') + Î³ V(s') ]
  ```
- Outputs `(V, policy)` dictionaries

### Simulation
- Starts from the `start_pos`
- Follows deterministic policy until terminal state
- Visited path is visually highlighted on the grid

---

## ğŸ’¾ File Save/Load Format

- **Rewards**: `{ "i,j": value, ... }`
- **Actions**: `{ "i,j": ["U","D",...], ... }`
- **Probs**: `{ "i,j|A": { "ni,nj": probability, ... }, ... }`

---


## ğŸ“œ License

MIT License â€” Feel free to modify and share.

---

## ğŸ‘¤ Author

**Reza Gooner**  
- GitHub: [@RezaGooner](https://github.com/RezaGooner)  
- Email: RezaAsadiProgrammer@Gmail.com
